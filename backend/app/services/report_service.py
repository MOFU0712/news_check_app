import logging
from typing import List, Optional, Dict, Any, Tuple
from datetime import datetime, timedelta, timezone
from sqlalchemy.orm import Session
from sqlalchemy import func, desc, and_, or_
import csv
import io
import uuid
import json
from collections import defaultdict, Counter
import pytz

from app.models.article import Article
from app.core.config import settings
from app.models.user import User
from app.models.saved_report import SavedReport
from app.models.prompt import PromptTemplate
from app.services.llm_service import llm_service

logger = logging.getLogger(__name__)


def make_json_serializable(obj):
    """ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’JSON serializableã«å¤‰æ›"""
    if isinstance(obj, uuid.UUID):
        return str(obj)
    elif isinstance(obj, datetime):
        return obj.isoformat()
    elif isinstance(obj, dict):
        return {key: make_json_serializable(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [make_json_serializable(item) for item in obj]
    else:
        return obj


class ReportService:
    """ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆãƒ»åˆ†æã‚µãƒ¼ãƒ“ã‚¹"""
    
    def __init__(self, db: Session):
        self.db = db
        self.llm_service = llm_service
    
    async def generate_report(
        self,
        report_type: str,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        tags: Optional[List[str]] = None,
        sources: Optional[List[str]] = None,
        user: Optional[User] = None
    ) -> Dict[str, Any]:
        """æŒ‡å®šã•ã‚ŒãŸæ¡ä»¶ã§ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        
        # æ—¥ä»˜ç¯„å›²ã®å‡¦ç†
        date_filter = self._build_date_filter(start_date, end_date)
        
        if report_type == "summary":
            return await self._generate_summary_report(date_filter, tags, sources)
        elif report_type == "tag_analysis":
            return await self._generate_tag_analysis_report(date_filter, tags, sources)
        elif report_type == "source_analysis":
            return await self._generate_source_analysis_report(date_filter, sources)
        elif report_type == "trend_analysis":
            return await self._generate_trend_analysis_report(date_filter, tags, sources)
        else:
            raise ValueError(f"ã‚µãƒãƒ¼ãƒˆã•ã‚Œã¦ã„ãªã„ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—: {report_type}")
    
    def _build_date_filter(self, start_date: Optional[str], end_date: Optional[str]) -> Tuple[Optional[datetime], Optional[datetime]]:
        """æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’æ§‹ç¯‰"""
        start_dt = None
        end_dt = None
        
        logger.info(f"Building date filter: start_date={start_date}, end_date={end_date}")
        
        if start_date:
            try:
                start_dt = datetime.fromisoformat(start_date.replace('Z', '+00:00'))
                logger.info(f"Parsed start_date: {start_dt}")
            except ValueError:
                logger.warning(f"Invalid start_date format: {start_date}")
        
        if end_date:
            try:
                end_dt = datetime.fromisoformat(end_date.replace('Z', '+00:00'))
                
                # çµ‚äº†æ—¥æ™‚ã‚’23:59:59.999999ã«è¨­å®šï¼ˆãã®æ—¥ã®æœ€å¾Œã®ç¬é–“ï¼‰
                if end_dt.hour == 0 and end_dt.minute == 0 and end_dt.second == 0 and end_dt.microsecond == 0:
                    end_dt = end_dt.replace(hour=23, minute=59, second=59, microsecond=999999)
                    logger.info(f"Adjusted end_date to end of day: {end_dt}")
                else:
                    logger.info(f"Parsed end_date (no adjustment): {end_dt}")
                
            except ValueError:
                logger.warning(f"Invalid end_date format: {end_date}")
        
        logger.info(f"Final date filter: start_dt={start_dt}, end_dt={end_dt}")
        return start_dt, end_dt
    
    async def _generate_summary_report(
        self,
        date_filter: Tuple[Optional[datetime], Optional[datetime]],
        tags: Optional[List[str]] = None,
        sources: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """è¦ç´„ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        start_dt, end_dt = date_filter
        query = self.db.query(Article)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
        if start_dt:
            query = query.filter(Article.published_date >= start_dt)
        if end_dt:
            query = query.filter(Article.published_date <= end_dt)
        if tags:
            for tag in tags:
                query = query.filter(Article.tags.any(tag))
        if sources:
            query = query.filter(Article.source.in_(sources))
        
        articles = query.all()
        total_count = len(articles)
        
        # åŸºæœ¬çµ±è¨ˆ
        tag_counter = Counter()
        source_counter = Counter()
        daily_counts = defaultdict(int)
        
        for article in articles:
            # ã‚¿ã‚°çµ±è¨ˆ
            if article.tags:
                for tag in article.tags:
                    tag_counter[tag] += 1
            
            # ã‚½ãƒ¼ã‚¹çµ±è¨ˆ
            if article.source:
                source_counter[article.source] += 1
            
            # æ—¥åˆ¥çµ±è¨ˆ
            date_str = article.published_date.strftime('%Y-%m-%d')
            daily_counts[date_str] += 1
        
        # äººæ°—ã®ã‚¿ã‚°ãƒ»ã‚½ãƒ¼ã‚¹ï¼ˆä¸Šä½10ä»¶ï¼‰
        popular_tags = tag_counter.most_common(10)
        popular_sources = source_counter.most_common(10)
        
        # è¨˜äº‹è¦ç´„ãƒªã‚¹ãƒˆï¼ˆå…¨è¨˜äº‹ã‚’å«ã‚ã‚‹ï¼‰
        article_summaries = []
        for article in articles:
            if article.summary and len(article.summary.strip()) > 10:
                article_summaries.append({
                    "title": article.title,
                    "summary": article.summary,
                    "url": article.url,
                    "source": article.source,
                    "published_date": article.published_date.isoformat(),
                    "tags": article.tags or []
                })
        
        # è¦ç´„æ–‡ã‚’ç”Ÿæˆ
        period_text = ""
        if start_dt and end_dt:
            period_text = f"{start_dt.strftime('%Yå¹´%mæœˆ%dæ—¥')}ã‹ã‚‰{end_dt.strftime('%Yå¹´%mæœˆ%dæ—¥')}ã¾ã§"
        elif start_dt:
            period_text = f"{start_dt.strftime('%Yå¹´%mæœˆ%dæ—¥')}ä»¥é™"
        elif end_dt:
            period_text = f"{end_dt.strftime('%Yå¹´%mæœˆ%dæ—¥')}ã¾ã§"
        else:
            period_text = "å…¨æœŸé–“"
        
        summary = f"{period_text}ã®è¨˜äº‹ãƒ¬ãƒãƒ¼ãƒˆ: åˆè¨ˆ{total_count}ä»¶ã®è¨˜äº‹ã‚’åˆ†æã€‚"
        if popular_tags:
            summary += f" äººæ°—ã®ã‚¿ã‚°ã¯ã€Œ{popular_tags[0][0]}ã€({popular_tags[0][1]}ä»¶)ã€‚"
        if popular_sources:
            summary += f" ä¸»è¦ãªã‚½ãƒ¼ã‚¹ã¯ã€Œ{popular_sources[0][0]}ã€({popular_sources[0][1]}ä»¶)ã€‚"
        
        return {
            "data": {
                "total_articles": total_count,
                "popular_tags": popular_tags,
                "popular_sources": popular_sources,
                "daily_counts": dict(daily_counts),
                "article_summaries": article_summaries,
                "period": {"start": start_dt.isoformat() if start_dt else None, "end": end_dt.isoformat() if end_dt else None}
            },
            "summary": summary
        }
    
    async def _generate_tag_analysis_report(
        self,
        date_filter: Tuple[Optional[datetime], Optional[datetime]],
        tags: Optional[List[str]] = None,
        sources: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """ã‚¿ã‚°åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        start_dt, end_dt = date_filter
        query = self.db.query(Article)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
        if start_dt:
            query = query.filter(Article.published_date >= start_dt)
        if end_dt:
            query = query.filter(Article.published_date <= end_dt)
        if sources:
            query = query.filter(Article.source.in_(sources))
        
        articles = query.all()
        
        # ã‚¿ã‚°ã”ã¨ã®è©³ç´°åˆ†æ
        tag_analysis = defaultdict(lambda: {
            "count": 0,
            "sources": Counter(),
            "recent_articles": [],
            "trend": []
        })
        
        for article in articles:
            if article.tags:
                for tag in article.tags:
                    if not tags or tag in tags:  # æŒ‡å®šã‚¿ã‚°ã®ã¿ã¾ãŸã¯å…¨ã‚¿ã‚°
                        tag_analysis[tag]["count"] += 1
                        if article.source:
                            tag_analysis[tag]["sources"][article.source] += 1
                        
                        # æœ€è¿‘ã®è¨˜äº‹ï¼ˆ5ä»¶ã¾ã§ï¼‰
                        if len(tag_analysis[tag]["recent_articles"]) < 5:
                            tag_analysis[tag]["recent_articles"].append({
                                "title": article.title,
                                "url": article.url,
                                "published_date": article.published_date.isoformat(),
                                "source": article.source
                            })
        
        # çµæœã‚’ã‚½ãƒ¼ãƒˆï¼ˆè¨˜äº‹æ•°é †ï¼‰
        sorted_tags = sorted(tag_analysis.items(), key=lambda x: x[1]["count"], reverse=True)
        
        # è¨˜äº‹è¦ç´„ãƒªã‚¹ãƒˆï¼ˆå…¨è¨˜äº‹ã‚’å«ã‚ã‚‹ï¼‰
        article_summaries = []
        for article in articles:
            if article.summary and len(article.summary.strip()) > 10:
                article_summaries.append({
                    "title": article.title,
                    "summary": article.summary,
                    "url": article.url,
                    "source": article.source,
                    "published_date": article.published_date.isoformat(),
                    "tags": article.tags or []
                })
        
        summary = f"ã‚¿ã‚°åˆ†æ: {len(sorted_tags)}å€‹ã®ã‚¿ã‚°ã‚’åˆ†æã€‚"
        if sorted_tags:
            top_tag = sorted_tags[0]
            summary += f" æœ€ã‚‚å¤šã„ã‚¿ã‚°ã¯ã€Œ{top_tag[0]}ã€({top_tag[1]['count']}ä»¶)ã€‚"
        
        return {
            "data": {
                "tag_analysis": dict(sorted_tags[:20]),  # ä¸Šä½20ä»¶
                "total_unique_tags": len(sorted_tags),
                "article_summaries": article_summaries
            },
            "summary": summary
        }
    
    async def _generate_source_analysis_report(
        self,
        date_filter: Tuple[Optional[datetime], Optional[datetime]],
        sources: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """ã‚½ãƒ¼ã‚¹åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        start_dt, end_dt = date_filter
        query = self.db.query(Article)
        
        # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨
        if start_dt:
            query = query.filter(Article.published_date >= start_dt)
        if end_dt:
            query = query.filter(Article.published_date <= end_dt)
        if sources:
            query = query.filter(Article.source.in_(sources))
        
        articles = query.all()
        
        # ã‚½ãƒ¼ã‚¹ã”ã¨ã®è©³ç´°åˆ†æ
        source_analysis = defaultdict(lambda: {
            "count": 0,
            "tags": Counter(),
            "recent_articles": [],
            "daily_counts": defaultdict(int)
        })
        
        for article in articles:
            if article.source:
                source = article.source
                source_analysis[source]["count"] += 1
                
                # ã‚¿ã‚°çµ±è¨ˆ
                if article.tags:
                    for tag in article.tags:
                        source_analysis[source]["tags"][tag] += 1
                
                # æœ€è¿‘ã®è¨˜äº‹ï¼ˆ5ä»¶ã¾ã§ï¼‰
                if len(source_analysis[source]["recent_articles"]) < 5:
                    source_analysis[source]["recent_articles"].append({
                        "title": article.title,
                        "url": article.url,
                        "published_date": article.published_date.isoformat()
                    })
                
                # æ—¥åˆ¥çµ±è¨ˆ
                date_str = article.published_date.strftime('%Y-%m-%d')
                source_analysis[source]["daily_counts"][date_str] += 1
        
        # çµæœã‚’ã‚½ãƒ¼ãƒˆ
        sorted_sources = sorted(source_analysis.items(), key=lambda x: x[1]["count"], reverse=True)
        
        # è¨˜äº‹è¦ç´„ãƒªã‚¹ãƒˆï¼ˆå…¨è¨˜äº‹ã‚’å«ã‚ã‚‹ï¼‰
        article_summaries = []
        for article in articles:
            if article.summary and len(article.summary.strip()) > 10:
                article_summaries.append({
                    "title": article.title,
                    "summary": article.summary,
                    "url": article.url,
                    "source": article.source,
                    "published_date": article.published_date.isoformat(),
                    "tags": article.tags or []
                })
        
        summary = f"ã‚½ãƒ¼ã‚¹åˆ†æ: {len(sorted_sources)}å€‹ã®ã‚½ãƒ¼ã‚¹ã‚’åˆ†æã€‚"
        if sorted_sources:
            top_source = sorted_sources[0]
            summary += f" æœ€ã‚‚å¤šã„ã‚½ãƒ¼ã‚¹ã¯ã€Œ{top_source[0]}ã€({top_source[1]['count']}ä»¶)ã€‚"
        
        return {
            "data": {
                "source_analysis": dict(sorted_sources[:20]),  # ä¸Šä½20ä»¶
                "total_unique_sources": len(sorted_sources),
                "article_summaries": article_summaries
            },
            "summary": summary
        }
    
    async def _generate_trend_analysis_report(
        self,
        date_filter: Tuple[Optional[datetime], Optional[datetime]],
        tags: Optional[List[str]] = None,
        sources: Optional[List[str]] = None
    ) -> Dict[str, Any]:
        """ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        start_dt, end_dt = date_filter
        
        logger.info(f"Generating trend analysis report with date_filter: start_dt={start_dt}, end_dt={end_dt}")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§éå»30æ—¥é–“
        if not start_dt:
            start_dt = datetime.now(pytz.timezone(settings.TIMEZONE)) - timedelta(days=30)
            logger.info(f"Using default start_dt: {start_dt}")
        if not end_dt:
            end_dt = datetime.now(pytz.timezone(settings.TIMEZONE))
            logger.info(f"Using default end_dt: {end_dt}")
        
        logger.info(f"Final date range for query: {start_dt} to {end_dt}")
        
        # å…¨è¨˜äº‹æ•°ã‚’ã¾ãšç¢ºèª
        total_articles = self.db.query(Article).count()
        logger.info(f"Total articles in database: {total_articles}")
        
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿å‰ã®ã‚¯ã‚¨ãƒª
        base_query = self.db.query(Article)
        
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ã‚’é©ç”¨
        query = base_query.filter(
            Article.published_date >= start_dt,
            Article.published_date <= end_dt
        )
        
        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿å¾Œã®ä»¶æ•°ã‚’ãƒ­ã‚°å‡ºåŠ›
        date_filtered_count = query.count()
        logger.info(f"Articles after date filtering ({start_dt} to {end_dt}): {date_filtered_count}")
        
        if tags:
            logger.info(f"Applying tag filter: {tags}")
            for tag in tags:
                query = query.filter(Article.tags.any(tag))
        if sources:
            logger.info(f"Applying source filter: {sources}")
            query = query.filter(Article.source.in_(sources))
        
        articles = query.all()
        logger.info(f"Final filtered articles count: {len(articles)}")
        
        # ãƒ‡ãƒãƒƒã‚°: æœ€åˆã®3è¨˜äº‹ã®æƒ…å ±ã‚’è¡¨ç¤º
        if articles:
            logger.info("Sample articles found:")
            for i, article in enumerate(articles[:3]):
                logger.info(f"  Article {i+1}: title='{article.title[:50]}...', published_date={article.published_date}")
        else:
            logger.warning("No articles found matching the criteria!")
            
            # ãƒ‡ãƒãƒƒã‚°: è¨˜äº‹ã®æ—¥ä»˜ç¯„å›²ã‚’ç¢ºèª
            date_range_query = self.db.query(
                func.min(Article.published_date).label('min_date'),
                func.max(Article.published_date).label('max_date')
            ).first()
            if date_range_query:
                logger.info(f"Available article date range: {date_range_query.min_date} to {date_range_query.max_date}")
        
        # æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰
        daily_trends = defaultdict(lambda: {
            "count": 0,
            "tags": Counter(),
            "sources": Counter()
        })
        
        for article in articles:
            date_str = article.published_date.strftime('%Y-%m-%d')
            daily_trends[date_str]["count"] += 1
            
            if article.tags:
                for tag in article.tags:
                    daily_trends[date_str]["tags"][tag] += 1
            
            if article.source:
                daily_trends[date_str]["sources"][article.source] += 1
        
        # é€±åˆ¥é›†è¨ˆ
        weekly_trends = defaultdict(int)
        for article in articles:
            week_start = article.published_date - timedelta(days=article.published_date.weekday())
            week_key = week_start.strftime('%Y-%m-%d')
            weekly_trends[week_key] += 1
        
        # è¨˜äº‹è¦ç´„ãƒªã‚¹ãƒˆï¼ˆå…¨è¨˜äº‹ã‚’å«ã‚ã‚‹ï¼‰
        article_summaries = []
        for article in articles:
            if article.summary and len(article.summary.strip()) > 10:
                article_summaries.append({
                    "title": article.title,
                    "summary": article.summary,
                    "url": article.url,
                    "source": article.source,
                    "published_date": article.published_date.isoformat(),
                    "tags": article.tags or []
                })
        
        summary = f"ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ: {start_dt.strftime('%Yå¹´%mæœˆ%dæ—¥')}ã‹ã‚‰{end_dt.strftime('%Yå¹´%mæœˆ%dæ—¥')}ã¾ã§ã®{len(articles)}ä»¶ã®è¨˜äº‹ã‚’åˆ†æã€‚"
        
        return {
            "data": {
                "daily_trends": dict(daily_trends),
                "weekly_trends": dict(weekly_trends),
                "article_summaries": article_summaries,
                "period": {
                    "start": start_dt.isoformat(),
                    "end": end_dt.isoformat()
                },
                "total_articles": len(articles)
            },
            "summary": summary
        }
    
    async def export_articles_csv(
        self,
        query: Optional[str] = None,
        tags: Optional[List[str]] = None,
        source: Optional[str] = None,
        start_date: Optional[str] = None,
        end_date: Optional[str] = None,
        user: Optional[User] = None
    ) -> str:
        """è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’CSVå½¢å¼ã§ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""
        
        # ã‚¯ã‚¨ãƒªæ§‹ç¯‰
        db_query = self.db.query(Article)
        
        if query:
            db_query = db_query.filter(
                or_(
                    Article.title.ilike(f"%{query}%"),
                    Article.content.ilike(f"%{query}%"),
                    Article.summary.ilike(f"%{query}%")
                )
            )
        
        if tags:
            for tag in tags:
                db_query = db_query.filter(Article.tags.any(tag))
        
        if source:
            db_query = db_query.filter(Article.source.ilike(f"%{source}%"))
        
        if start_date:
            start_dt = datetime.fromisoformat(start_date.replace('Z', '+00:00'))
            db_query = db_query.filter(Article.published_date >= start_dt)
        
        if end_date:
            end_dt = datetime.fromisoformat(end_date.replace('Z', '+00:00'))
            db_query = db_query.filter(Article.published_date <= end_dt)
        
        articles = db_query.order_by(desc(Article.published_date)).all()
        
        # CSVä½œæˆ
        output = io.StringIO()
        writer = csv.writer(output)
        
        # ãƒ˜ãƒƒãƒ€ãƒ¼
        writer.writerow([
            'ID',
            'ã‚¿ã‚¤ãƒˆãƒ«',
            'URL',
            'ã‚½ãƒ¼ã‚¹',
            'è¦ç´„',
            'ã‚¿ã‚°',
            'å…¬é–‹æ—¥',
            'å–å¾—æ—¥',
            'ä½œæˆè€…ID'
        ])
        
        # ãƒ‡ãƒ¼ã‚¿è¡Œ
        for article in articles:
            writer.writerow([
                str(article.id),
                article.title or '',
                article.url or '',
                article.source or '',
                article.summary or '',
                ', '.join(article.tags) if article.tags else '',
                article.published_date.isoformat() if article.published_date else '',
                article.published_date.isoformat() if article.published_date else '',
                str(article.created_by) if article.created_by else ''
            ])
        
        return output.getvalue()
    
    async def get_analytics_overview(
        self,
        days: int = 30,
        user: Optional[User] = None
    ) -> Dict[str, Any]:
        """åˆ†ææ¦‚è¦ã‚’å–å¾—ï¼ˆè¦ç´„æ–‡å«ã‚€ï¼‰"""
        end_date = datetime.now(pytz.timezone(settings.TIMEZONE))
        start_date = end_date - timedelta(days=days)
        
        # åŸºæœ¬çµ±è¨ˆ
        total_articles = self.db.query(Article).count()
        period_articles = self.db.query(Article).filter(
            Article.published_date >= start_date
        ).count()
        
        # æœŸé–“å†…ã®è¨˜äº‹ã‚’å–å¾—ï¼ˆè¦ç´„æ–‡å«ã‚€ï¼‰
        recent_articles = self.db.query(Article).filter(
            Article.published_date >= start_date
        ).order_by(Article.published_date.desc()).all()
        
        # è¨˜äº‹è¦ç´„ãƒªã‚¹ãƒˆï¼ˆä¸Šä½è¨˜äº‹ï¼‰
        article_summaries = []
        for article in recent_articles:
            if article.summary and len(article.summary.strip()) > 10:
                article_summaries.append({
                    "title": article.title,
                    "summary": article.summary,
                    "url": article.url,
                    "source": article.source,
                    "published_date": article.published_date.isoformat(),
                    "tags": article.tags or []
                })
        
        # æ—¥åˆ¥è¨˜äº‹æ•°
        daily_query = self.db.query(
            func.date(Article.published_date).label('date'),
            func.count().label('count')
        ).filter(
            Article.published_date >= start_date
        ).group_by(func.date(Article.published_date))
        
        daily_data = {str(row.date): row.count for row in daily_query.all()}
        
        # ãƒˆãƒƒãƒ—ã‚¿ã‚°
        articles_with_tags = self.db.query(Article).filter(
            Article.published_date >= start_date,
            Article.tags.isnot(None)
        ).all()
        
        tag_counter = Counter()
        for article in articles_with_tags:
            if article.tags:
                for tag in article.tags:
                    tag_counter[tag] += 1
        
        top_tags = tag_counter.most_common(10)
        
        # ãƒˆãƒƒãƒ—ã‚½ãƒ¼ã‚¹
        source_query = self.db.query(
            Article.source,
            func.count().label('count')
        ).filter(
            Article.published_date >= start_date,
            Article.source.isnot(None)
        ).group_by(Article.source).order_by(desc('count')).limit(10)
        
        top_sources = [(row.source, row.count) for row in source_query.all()]
        
        return {
            "period": {
                "days": days,
                "start_date": start_date.isoformat(),
                "end_date": end_date.isoformat()
            },
            "statistics": {
                "total_articles": total_articles,
                "period_articles": period_articles,
                "daily_average": round(period_articles / days, 1)
            },
            "daily_data": daily_data,
            "top_tags": top_tags,
            "top_sources": top_sources,
            "article_summaries": article_summaries  # å…¨ä»¶ã‚’å«ã‚ã‚‹
        }
    
    async def get_tag_trends(
        self,
        days: int = 30,
        limit: int = 20,
        user: Optional[User] = None
    ) -> Dict[str, Any]:
        """ã‚¿ã‚°ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—"""
        end_date = datetime.now(pytz.timezone(settings.TIMEZONE))
        start_date = end_date - timedelta(days=days)
        
        articles = self.db.query(Article).filter(
            Article.published_date >= start_date,
            Article.tags.isnot(None)
        ).all()
        
        # æ—¥åˆ¥ã‚¿ã‚°çµ±è¨ˆ
        daily_tag_counts = defaultdict(lambda: Counter())
        
        for article in articles:
            date_str = article.published_date.strftime('%Y-%m-%d')
            if article.tags:
                for tag in article.tags:
                    daily_tag_counts[date_str][tag] += 1
        
        # ãƒˆãƒ¬ãƒ³ãƒ‰è¨ˆç®—ï¼ˆæœ€è¿‘ã®å¢—åŠ ç‡ãªã©ï¼‰
        tag_trends = {}
        all_tags = Counter()
        
        for article in articles:
            if article.tags:
                for tag in article.tags:
                    all_tags[tag] += 1
        
        # ä¸Šä½ã‚¿ã‚°ã®ã¿å‡¦ç†
        top_tags = [tag for tag, _ in all_tags.most_common(limit)]
        
        for tag in top_tags:
            daily_counts = []
            for i in range(days):
                date = start_date + timedelta(days=i)
                date_str = date.strftime('%Y-%m-%d')
                count = daily_tag_counts[date_str][tag]
                daily_counts.append(count)
            
            tag_trends[tag] = {
                "total_count": all_tags[tag],
                "daily_counts": daily_counts,
                "average_daily": sum(daily_counts) / len(daily_counts)
            }
        
        return {
            "period": {
                "days": days,
                "start_date": start_date.isoformat(),
                "end_date": end_date.isoformat()
            },
            "tag_trends": tag_trends
        }
    
    async def get_source_trends(
        self,
        days: int = 30,
        limit: int = 20,
        user: Optional[User] = None
    ) -> Dict[str, Any]:
        """ã‚½ãƒ¼ã‚¹ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’å–å¾—"""
        end_date = datetime.now(pytz.timezone(settings.TIMEZONE))
        start_date = end_date - timedelta(days=days)
        
        # ã‚½ãƒ¼ã‚¹åˆ¥æ—¥åˆ¥çµ±è¨ˆ
        daily_query = self.db.query(
            func.date(Article.published_date).label('date'),
            Article.source,
            func.count().label('count')
        ).filter(
            Article.published_date >= start_date,
            Article.source.isnot(None)
        ).group_by(
            func.date(Article.published_date),
            Article.source
        )
        
        daily_source_counts = defaultdict(lambda: defaultdict(int))
        all_sources = Counter()
        
        for row in daily_query.all():
            date_str = str(row.date)
            source = row.source
            count = row.count
            
            daily_source_counts[date_str][source] = count
            all_sources[source] += count
        
        # ä¸Šä½ã‚½ãƒ¼ã‚¹ã®ãƒˆãƒ¬ãƒ³ãƒ‰
        top_sources = [source for source, _ in all_sources.most_common(limit)]
        source_trends = {}
        
        for source in top_sources:
            daily_counts = []
            for i in range(days):
                date = start_date + timedelta(days=i)
                date_str = date.strftime('%Y-%m-%d')
                count = daily_source_counts[date_str][source]
                daily_counts.append(count)
            
            source_trends[source] = {
                "total_count": all_sources[source],
                "daily_counts": daily_counts,
                "average_daily": sum(daily_counts) / len(daily_counts)
            }
        
        return {
            "period": {
                "days": days,
                "start_date": start_date.isoformat(),
                "end_date": end_date.isoformat()
            },
            "source_trends": source_trends
        }
    
    async def generate_blog_report(
        self,
        report_type: str,
        report_data: Dict[str, Any],
        summary: str,
        title: str,
        user: Optional[User] = None,
        prompt_template_id: Optional[str] = None
    ) -> str:
        """åˆ†æãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ–ãƒ­ã‚°è¨˜äº‹å½¢å¼ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        
        print(f"=== LLM service is_available: {llm_service.is_available()} ===")
        if not llm_service.is_available():
            logger.warning("LLM service not available. Generating basic report.")
            logger.info(f"LLM service client status: {llm_service.client}")
            return self._generate_basic_blog_report(report_type, report_data, summary, title)
        
        print("=== LLM service is available, proceeding with template check ===")
        
        # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        custom_template = None
        logger.info(f"Checking for custom template: template_id={prompt_template_id}, user_id={user.id if user else 'None'}")
        
        if prompt_template_id and user:
            # ã¾ãšãƒ¦ãƒ¼ã‚¶ãƒ¼ä½œæˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç¢ºèª
            custom_template = self.db.query(PromptTemplate).filter(
                PromptTemplate.id == prompt_template_id,
                PromptTemplate.created_by == str(user.id)  # æ˜ç¤ºçš„ã«æ–‡å­—åˆ—ã«å¤‰æ›
                # template_typeæ¡ä»¶ã‚’å‰Šé™¤ã—ã¦ã‚ˆã‚ŠæŸ”è»Ÿã«
            ).first()
            
            if custom_template:
                logger.info(f"Found user custom template: {custom_template.name}")
            else:
                logger.warning(f"User custom template not found: template_id={prompt_template_id}, user_id={user.id}, type={type(user.id)}")
                # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚‚ãƒã‚§ãƒƒã‚¯
                default_template = self.db.query(PromptTemplate).filter(
                    PromptTemplate.id == prompt_template_id,
                    PromptTemplate.created_by == "system-default-user-id"
                ).first()
                if default_template:
                    logger.info(f"Using default template instead: {default_template.name}")
                    custom_template = default_template
                else:
                    # æœ€å¾Œã«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆIDã ã‘ã§æ¤œç´¢
                    any_template = self.db.query(PromptTemplate).filter(
                        PromptTemplate.id == prompt_template_id
                    ).first()
                    if any_template:
                        logger.info(f"Found template by ID only: {any_template.name}, created_by={any_template.created_by}")
                        custom_template = any_template
                    else:
                        logger.error(f"No template found with ID: {prompt_template_id}")
        
        if custom_template:
            logger.info(f"Using template: {custom_template.name}, system_prompt length: {len(custom_template.system_prompt or '')}")
        else:
            logger.info("No custom template will be used, using default behavior")
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰
        report_context = self._build_report_context(report_type, report_data, summary)
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆé¸æŠï¼ˆã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ or ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
        if custom_template:
            # ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨
            system_prompt = custom_template.system_prompt or custom_template.template or ""
            if custom_template.user_prompt_template:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒã‚ã‚‹å ´åˆã¯å®‰å…¨ã«ç½®æ›
                try:
                    # è¨˜äº‹ã®URLä¸€è¦§ã¨ã‚¿ã‚¤ãƒˆãƒ«ä¸€è¦§ã‚’æŠ½å‡º
                    article_summaries = report_data.get("data", {}).get("article_summaries", [])
                    article_urls = [article.get('url', '') for article in article_summaries]
                    article_titles = [article.get('title', '') for article in article_summaries]
                    
                    # ç”Ÿã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆï¼ˆæ§‹é€ åŒ–ã•ã‚Œã¦ã„ãªã„ã‚·ãƒ³ãƒ—ãƒ«ãªå½¢å¼ï¼‰
                    raw_articles = []
                    for i, article in enumerate(article_summaries, 1):
                        raw_article = f"ãƒ‹ãƒ¥ãƒ¼ã‚¹{i}: {article.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')}\n"
                        raw_article += f"è¦ç´„: {article.get('summary', 'è¦ç´„ãªã—')}\n"
                        raw_article += f"URL: {article.get('url', 'URLãªã—')}\n"
                        if article.get('tags'):
                            raw_article += f"ã‚¿ã‚°: {', '.join(article.get('tags', []))}\n"
                        raw_articles.append(raw_article)
                    
                    articles_text = '\n'.join(raw_articles)
                    
                    # æ—¥ä»˜æƒ…å ±ã‚’å–å¾—
                    period_info = report_data.get("data", {}).get('period', {})
                    start_date = period_info.get('start', '')
                    end_date = period_info.get('end', '')
                    
                    # ä½¿ç”¨å¯èƒ½ãªå¤‰æ•°ã‚’å®šç¾©
                    template_vars = {
                        'title': title,
                        'report_context': report_context,
                        'report_type': report_type,
                        'datetime': datetime.now(pytz.timezone(settings.TIMEZONE)).strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M'),
                        'summary': summary,
                        'content': report_context,
                        'data': str(report_data),
                        'news_data': articles_text,  # ç”Ÿã®ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿
                        'articles': articles_text,   # ç”Ÿã®è¨˜äº‹ãƒ‡ãƒ¼ã‚¿
                        'news_information': articles_text,  # ç”Ÿã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±
                        'article_urls': '\n'.join(article_urls),  # URLä¸€è¦§
                        'article_titles': '\n'.join(article_titles),  # ã‚¿ã‚¤ãƒˆãƒ«ä¸€è¦§
                        'article_count': len(article_summaries),  # è¨˜äº‹æ•°
                        'start_date': start_date,  # é–‹å§‹æ—¥
                        'end_date': end_date  # çµ‚äº†æ—¥
                    }
                    
                    # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã®å¤‰æ•°ã‚’å®‰å…¨ã«ç½®æ›
                    import re
                    template_text = custom_template.user_prompt_template
                    
                    # åˆ©ç”¨å¯èƒ½ãªå¤‰æ•°ã®ã¿ã‚’ç½®æ›ï¼ˆå­˜åœ¨ã—ãªã„å¤‰æ•°ã¯ãã®ã¾ã¾æ®‹ã™ï¼‰
                    for var_name, var_value in template_vars.items():
                        template_text = template_text.replace(f'{{{var_name}}}', str(var_value))
                    
                    # æ®‹ã£ãŸå¤‰æ•°ã¯ç©ºæ–‡å­—ã«ç½®æ›ï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ï¼‰
                    template_text = re.sub(r'\{[^}]+\}', '', template_text)
                    
                    # ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ãã®ã¾ã¾ä½¿ç”¨ï¼ˆãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ã®æŒ¿å…¥ã¯ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå´ã§åˆ¶å¾¡ï¼‰
                    prompt = template_text
                    
                except Exception as e:
                    logger.warning(f"Template formatting failed: {e}, using fallback")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ‹ãƒ¥ãƒ¼ã‚¹ãƒ‡ãƒ¼ã‚¿ä»˜ãã‚·ãƒ³ãƒ—ãƒ«ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                    prompt = f"""
## å…·ä½“çš„ãªãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ãŒæä¾›ã•ã‚Œã¦ã„ã¾ã™

ä»¥ä¸‹ã¯æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã®ITãƒ»AIãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã§ã™ï¼š

{report_context}

---

ä¸Šè¨˜ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ã‚’ä½¿ã£ã¦ã€ã‚¿ã‚¤ãƒˆãƒ«ã€Œ{title}ã€ã§ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã€Œ{report_type}ã€ã®è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
"""
            else:
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒãªã„å ´åˆã®ã‚·ãƒ³ãƒ—ãƒ«ãªæ§‹æˆ
                prompt = f"ã‚¿ã‚¤ãƒˆãƒ«ã€Œ{title}ã€ã§{report_type}ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
            
            model_name = custom_template.model_name
            max_tokens = custom_template.max_tokens
            temperature = custom_template.temperature
            
            logger.info(f"Using custom prompt template: {custom_template.name}")
            
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨
            system_prompt = "ã‚ãªãŸã¯çµŒé¨“è±Šå¯Œãªãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆå…¼ãƒ©ã‚¤ã‚¿ãƒ¼ã§ã™ã€‚"
            
            prompt = f"""
ä»¥ä¸‹ã®ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†æã—ã¦ã€AIã‚„ITæ¥­ç•Œã«èˆˆå‘³ã®ã‚ã‚‹ãƒ©ã‚¤ãƒˆå±¤èª­è€…å‘ã‘ã«ã€
ã€Œ3åˆ†ã§èª­ã‚ã‚‹ã€ã‚ã‹ã‚Šã‚„ã™ã„ãƒˆãƒ¬ãƒ³ãƒ‰è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## åˆ†æãƒ‡ãƒ¼ã‚¿
{report_context}

## ã‚¿ãƒ¼ã‚²ãƒƒãƒˆèª­è€…
- AIã«èˆˆå‘³ãŒã‚ã‚‹ãŒå°‚é–€å®¶ã§ã¯ãªã„ä¸€èˆ¬ã®æ–¹
- æœ€æ–°æŠ€è¡“ã®å‹•å‘ã‚’æ‰‹è»½ã«çŸ¥ã‚ŠãŸã„ãƒ“ã‚¸ãƒã‚¹ãƒ‘ãƒ¼ã‚½ãƒ³
- ã‚¹ãƒãƒ›ã§èª­ã‚€ã“ã¨ãŒå¤šã„å¿™ã—ã„äººãŸã¡

## è¨˜äº‹æ§‹æˆè¦ä»¶

### 1. ã‚¿ã‚¤ãƒˆãƒ«: {title}

### 2. ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆç›®ç·šã®æ³¨ç›®TOP3
å„ãƒˆãƒ”ãƒƒã‚¯ã«ã¤ã„ã¦ï¼š
- ğŸ¥‡/ğŸ¥ˆ/ğŸ¥‰ [ãƒˆãƒ”ãƒƒã‚¯å]
- **å®Ÿå‹™ã§ä½¿ãˆãã†åº¦ï¼š** â˜…â˜…â˜…â˜…â˜…ï¼ˆ5æ®µéšï¼‰
- **æŠ€è¡“ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆåº¦ï¼š** â˜…â˜…â˜…â˜…â˜…ï¼ˆ5æ®µéšï¼‰
- **è©±é¡Œåº¦ï¼š** XXå›
- **â˜… å°‚é–€å®¶ã®ä¸€è¨€ã‚³ãƒ¡ãƒ³ãƒˆ**

## æ–‡ä½“ãƒ»è¡¨ç¾ã®ãƒ«ãƒ¼ãƒ«
- è¦ªã—ã¿ã‚„ã™ã„ä¸å¯§èªã§
- å°‚é–€ç”¨èªã¯å¿…ãšèª¬æ˜ã‚’æ·»ãˆã‚‹
- æ•°å­—ã‚’ä½¿ã£ã¦å…·ä½“æ€§ã‚’å‡ºã™
- å®Ÿç”¨æ€§ã‚’é‡è¦–

## å‡ºåŠ›å½¢å¼
Markdownå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

è¦ªã—ã¿ã‚„ã™ãã€ã§ã‚‚å°‚é–€æ€§ã®ã‚ã‚‹åˆ†æã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ã€‚
"""
            
            model_name = 'claude-3-7-sonnet-20250219'
            max_tokens = 2000
            temperature = 0.3

        try:
            print("=== About to call LLM API ===")
            # Claude APIã§ãƒ–ãƒ­ã‚°è¨˜äº‹ã‚’ç”Ÿæˆ
            messages = [{"role": "user", "content": prompt}]
            
            # systemãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’åˆ†é›¢ã—ã¦é€ä¿¡
            system_to_send = None
            if custom_template and system_prompt:
                system_to_send = system_prompt
                logger.info(f"Using custom system prompt: {system_prompt[:100]}...")
            
            print(f"=== Calling _api_call_with_retry with model: {model_name} ===")
            response = llm_service._api_call_with_retry(
                model=model_name,
                messages=messages,
                max_tokens=max_tokens,
                temperature=temperature,
                system=system_to_send
            )
            print("=== API call completed successfully ===")
            
            blog_content = llm_service.extract_text_from_response(response)
            
            # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®é–‹å§‹ãƒ»çµ‚äº†ã‚¿ã‚°ã‚’å‰Šé™¤
            blog_content = blog_content.replace('```markdown', '').replace('```', '')
            blog_content = blog_content.strip()
            
            logger.info(f"Generated blog report for {report_type}")
            return blog_content
            
        except Exception as e:
            logger.error(f"Error generating blog report: {e}")
            # API overloadã®å ´åˆã§ã‚‚ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’é©ç”¨ã—ãŸåŸºæœ¬ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
            if custom_template:
                logger.info("Using custom template for fallback basic report")
                return self._generate_basic_blog_report_with_template(report_type, report_data, summary, title, custom_template)
            return self._generate_basic_blog_report(report_type, report_data, summary, title)
    
    def _build_report_context(self, report_type: str, report_data: Dict[str, Any], summary: str) -> str:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè©³ç´°ãªã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ§‹ç¯‰"""
        
        context = f"## ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—: {report_type}\n"
        context += f"## åˆ†ææ¦‚è¦: {summary}\n\n"
        
        data = report_data.get("data", {})
        
        # ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ - å…¨è¨˜äº‹ã‚’æ˜ç¢ºã«æä¾›
        if "article_summaries" in data:
            summaries = data["article_summaries"]
            if summaries:
                # æ—¥ä»˜æƒ…å ±ã‚’å–å¾—
                period_info = data.get('period', {})
                start_date = period_info.get('start')
                end_date = period_info.get('end')
                
                context += f"## å…·ä½“çš„ãªITãƒ»AIãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ï¼ˆ{len(summaries)}ä»¶ï¼‰\n\n"
                
                if start_date and end_date:
                    start_dt = datetime.fromisoformat(start_date.replace('Z', '+00:00'))
                    end_dt = datetime.fromisoformat(end_date.replace('Z', '+00:00'))
                    context += f"**å¯¾è±¡æœŸé–“**: {start_dt.strftime('%Yå¹´%mæœˆ%dæ—¥')}ã‹ã‚‰{end_dt.strftime('%Yå¹´%mæœˆ%dæ—¥')}ã¾ã§ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹\n\n"
                
                context += "### ãƒ‹ãƒ¥ãƒ¼ã‚¹ä¸€è¦§ï¼š\n\n"
                
                for i, article in enumerate(summaries, 1):
                    # æ—¥ä»˜ã‚’æ•´å½¢ã—ã¦è¡¨ç¤º
                    published_date = article.get('published_date', '')
                    if published_date:
                        try:
                            date_obj = datetime.fromisoformat(published_date.replace('Z', '+00:00'))
                            date_str = date_obj.strftime('%mæœˆ%dæ—¥')
                        except:
                            date_str = ''
                    else:
                        date_str = ''
                    
                    context += f"**ãƒ‹ãƒ¥ãƒ¼ã‚¹{i}** ({date_str}): {article['title']}\n"
                    context += f"- **è¦ç´„**: {article['summary']}\n"
                    
                    # è¨˜äº‹ã®è©³ç´°æƒ…å ±ã‚’å–å¾—ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å®Œå…¨ãªè¨˜äº‹æƒ…å ±ã‚’å–å¾—ï¼‰
                    try:
                        from app.models.article import Article
                        full_article = self.db.query(Article).filter(Article.url == article['url']).first()
                        
                        # è¨˜äº‹ã®å†…å®¹ã®ä¸€éƒ¨ã‚‚å«ã‚ã‚‹ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰
                        if full_article and full_article.content and len(full_article.content.strip()) > 0:
                            content_text = full_article.content.strip()
                            # Markdownè¨˜æ³•ãªã©ã‚’ç°¡å˜ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                            import re
                            content_text = re.sub(r'[#*`\[\]]+', '', content_text)
                            content_text = re.sub(r'\n+', ' ', content_text)
                            content_preview = content_text[:500] + "..." if len(content_text) > 500 else content_text
                            if len(content_preview.strip()) > 10:  # æ„å‘³ã®ã‚ã‚‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤º
                                context += f"- **è¨˜äº‹å†…å®¹ã®ä¸€éƒ¨**: {content_preview}\n"
                        
                        # å…¬é–‹æ—¥ãŒã‚ã‚Œã°è¿½åŠ 
                        if full_article and full_article.published_date:
                            try:
                                pub_date = full_article.published_date.strftime('%Yå¹´%mæœˆ%dæ—¥')
                                context += f"- **å…¬é–‹æ—¥**: {pub_date}\n"
                            except:
                                pass
                    except Exception as e:
                        logger.debug(f"Could not fetch full article content for {article['url']}: {e}")
                    
                    context += f"- **æƒ…å ±ã‚½ãƒ¼ã‚¹**: {article['source']}\n"
                    if article.get('tags'):
                        context += f"- **é–¢é€£æŠ€è¡“ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {', '.join(article['tags'][:5])}\n"
                    context += f"- **å‚ç…§URL**: {article['url']}\n"
                    context += "\n"
                
                context += f"""
**é‡è¦ãªæŒ‡ç¤º**: 
- ä¸Šè¨˜ã¯å…·ä½“çš„ãªITãƒ»AIãƒ‹ãƒ¥ãƒ¼ã‚¹æƒ…å ±ï¼ˆ{len(summaries)}ä»¶ï¼‰ã§ã™
- å„ãƒ‹ãƒ¥ãƒ¼ã‚¹ã«ã¯**è¦ç´„**ã€**è¨˜äº‹å†…å®¹ã®ä¸€éƒ¨**ã€**å‚ç…§URL**ãŒå«ã¾ã‚Œã¦ã„ã¾ã™
- ã“ã‚Œã‚‰ã®è©³ç´°ãªæƒ…å ±ã‚’åŸºã«ã—ã¦ã€æŒ‡å®šã•ã‚ŒãŸå½¢å¼ã§è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„
- å‚ç…§URLã¯å¿…è¦ã«å¿œã˜ã¦è¨˜äº‹å†…ã§è¨€åŠã—ã¦ãã ã•ã„
- è¨˜äº‹å†…å®¹ã®ä¸€éƒ¨ã‚’å‚è€ƒã«ã€ã‚ˆã‚Šå…·ä½“çš„ã§è©³ç´°ãªåˆ†æã‚’è¡Œã£ã¦ãã ã•ã„

"""
            else:
                context += "## æ³¨æ„: æŒ‡å®šã•ã‚ŒãŸæœŸé–“ã«ãƒ‹ãƒ¥ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n\n"
        
        # ãƒ¬ãƒãƒ¼ãƒˆå›ºæœ‰ãƒ‡ãƒ¼ã‚¿
        if report_type == "summary":
            context += f"## çµ±è¨ˆãƒ‡ãƒ¼ã‚¿\n"
            context += f"- ç·è¨˜äº‹æ•°: {data.get('total_articles', 0)}ä»¶\n"
            
            popular_tags = data.get('popular_tags', [])
            if popular_tags:
                context += "\n### äººæ°—ã‚¿ã‚°ãƒ©ãƒ³ã‚­ãƒ³ã‚°\n"
                for i, (tag, count) in enumerate(popular_tags[:10], 1):
                    context += f"{i}. {tag}: {count}ä»¶\n"
            
            popular_sources = data.get('popular_sources', [])
            if popular_sources:
                context += "\n### ä¸»è¦ã‚½ãƒ¼ã‚¹ãƒ©ãƒ³ã‚­ãƒ³ã‚°\n"
                for i, (source, count) in enumerate(popular_sources[:10], 1):
                    context += f"{i}. {source}: {count}ä»¶\n"
                    
            # æ—¥åˆ¥ãƒ‡ãƒ¼ã‚¿
            daily_data = data.get('daily_data', {})
            if daily_data:
                context += "\n### æ—¥åˆ¥è¨˜äº‹æ•°æ¨ç§»\n"
                sorted_days = sorted(daily_data.items())[-7:]  # ç›´è¿‘7æ—¥
                for date, count in sorted_days:
                    context += f"- {date}: {count}ä»¶\n"
                    
        elif report_type == "tag_analysis":
            tag_analysis = data.get('tag_analysis', {})
            context += f"## ã‚¿ã‚°åˆ†æãƒ‡ãƒ¼ã‚¿\n"
            context += f"- åˆ†æå¯¾è±¡ã‚¿ã‚°æ•°: {data.get('total_unique_tags', 0)}\n\n"
            context += "### ä¸Šä½ã‚¿ã‚°ã®è©³ç´°åˆ†æ\n"
            for tag, info in list(tag_analysis.items())[:5]:
                context += f"#### ğŸ“Š {tag}\n"
                context += f"- è¨˜äº‹æ•°: {info['count']}ä»¶\n"
                if 'sources' in info:
                    top_sources = info['sources'].most_common(3)
                    context += f"- ä¸»è¦ã‚½ãƒ¼ã‚¹: {', '.join([f'{s}({c}ä»¶)' for s, c in top_sources])}\n"
                context += "\n"
                
        elif report_type == "source_analysis":
            source_analysis = data.get('source_analysis', {})
            context += f"## ã‚½ãƒ¼ã‚¹åˆ†æãƒ‡ãƒ¼ã‚¿\n"
            context += f"- åˆ†æå¯¾è±¡ã‚½ãƒ¼ã‚¹æ•°: {data.get('total_unique_sources', 0)}\n\n"
            context += "### ä¸Šä½ã‚½ãƒ¼ã‚¹ã®è©³ç´°åˆ†æ\n"
            for source, info in list(source_analysis.items())[:5]:
                context += f"#### ğŸ“° {source}\n"
                context += f"- è¨˜äº‹æ•°: {info['count']}ä»¶\n"
                if 'tags' in info:
                    top_tags = info['tags'].most_common(5)
                    context += f"- ä¸»è¦ã‚¿ã‚°: {', '.join([f'{t}({c}ä»¶)' for t, c in top_tags])}\n"
                context += "\n"
                
        elif report_type == "trend_analysis":
            context += f"## ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æãƒ‡ãƒ¼ã‚¿\n"
            context += f"- åˆ†ææœŸé–“ã®è¨˜äº‹æ•°: {data.get('total_articles', 0)}\n\n"
            daily_trends = data.get('daily_trends', {})
            if daily_trends:
                context += "### æ—¥åˆ¥ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆç›´è¿‘7æ—¥ï¼‰\n"
                sorted_trends = sorted(daily_trends.items())[-7:]
                for date, info in sorted_trends:
                    context += f"#### {date}\n"
                    context += f"- è¨˜äº‹æ•°: {info['count']}ä»¶\n"
                    if 'tags' in info:
                        top_tags = info['tags'].most_common(3)
                        context += f"- è©±é¡Œã®ã‚¿ã‚°: {', '.join([f'{t}({c})' for t, c in top_tags])}\n"
                    context += "\n"
        
        return context
    
    def _generate_basic_blog_report_with_template(
        self,
        report_type: str, 
        report_data: Dict[str, Any], 
        summary: str, 
        title: str,
        custom_template: 'PromptTemplate'
    ) -> str:
        """ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’é©ç”¨ã—ãŸçŸ¥çš„ãªãƒ–ãƒ­ã‚°ãƒ¬ãƒãƒ¼ãƒˆ"""
        logger.info(f"Generating intelligent fallback report with custom template: {custom_template.name}")
        
        # ãƒ‡ãƒ¼ã‚¿åˆ†æ
        data = report_data.get("data", {})
        
        # AIãƒ©ã‚¤ãƒˆå±¤å‘ã‘ã®ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        if "AIãƒ©ã‚¤ãƒˆå±¤å‘ã‘" in custom_template.name:
            return self._generate_ai_light_user_report(title, data, summary, custom_template)
        
        # ãã®ä»–ã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå‘ã‘
        return self._generate_smart_fallback_report(title, report_type, data, summary, custom_template)
    
    def _generate_ai_light_user_report(self, title: str, data: Dict, summary: str, template: 'PromptTemplate') -> str:
        """AIãƒ©ã‚¤ãƒˆå±¤å‘ã‘ã®çŸ¥çš„ãªãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        
        # ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ´å¯Ÿã‚’æŠ½å‡º
        # report_dataã®æ§‹é€ ã«å¿œã˜ã¦è¨˜äº‹æ•°ã‚’å–å¾—
        report_data = data.get('data', {})
        article_count = report_data.get('total_articles', 0)
        
        # daily_trendsã‹ã‚‰ã‚‚è¨˜äº‹æ•°ã‚’å–å¾—ï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
        if article_count == 0:
            daily_trends = report_data.get('daily_trends', {})
            article_count = sum(day_data.get('count', 0) for day_data in daily_trends.values())
        
        # top_tagsã‚’æŠ½å‡ºï¼ˆdaily_trendsã‹ã‚‰ç”Ÿæˆï¼‰
        top_tags = []
        daily_trends_data = report_data.get('daily_trends', {})
        if daily_trends_data:
            tag_counter = Counter()
            for day_data in daily_trends_data.values():
                if isinstance(day_data, dict) and 'tags' in day_data:
                    tag_counter.update(day_data['tags'])
            top_tags = tag_counter.most_common(5)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã§æ—¢å­˜ã®top_tagsã‚’ä½¿ç”¨
            top_tags = data.get('top_tags', [])[:5]
        
        # AIãƒ©ã‚¤ãƒˆå±¤å‘ã‘ã®è¦ªã—ã¿ã‚„ã™ã„è¨˜äº‹ã‚’ç”Ÿæˆ
        content = f"""# {title}

## ğŸ“± 3åˆ†ã§èª­ã‚ã‚‹AIãƒ»ITé€±åˆŠãƒˆãƒ¬ãƒ³ãƒ‰

ã“ã‚“ã«ã¡ã¯ï¼ä»Šé€±ã‚‚é¢ç™½ã„AIãƒ»ITãƒˆãƒ¬ãƒ³ãƒ‰ã‚’ãŠå±Šã‘ã—ã¾ã™ âœ¨

### ğŸ”¥ ä»Šé€±ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ

{self._create_friendly_summary(summary, article_count)}

### ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã§è¦‹ã‚‹ä»Šé€±ã®å‹•ã

**åˆ†æã—ãŸè¨˜äº‹æ•°**: {article_count}ä»¶
**æ³¨ç›®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**: {self._format_tags_for_light_users(top_tags)}

### ğŸ’¡ ä»Šé€±ã®æ°—ã«ãªã‚‹ãƒã‚¤ãƒ³ãƒˆ

{self._generate_light_user_insights(top_tags, data)}

### ğŸš€ æ¥é€±ã¸ã®å±•æœ›

{self._generate_outlook_for_light_users(top_tags)}

---

### ğŸ“š ç”¨èªè§£èª¬ã‚³ãƒ¼ãƒŠãƒ¼
{self._generate_glossary_for_tags(top_tags)}

---

*ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯æœ€æ–°ã®AIãƒˆãƒ¬ãƒ³ãƒ‰ã‚’3åˆ†ã§ç†è§£ã§ãã‚‹ã‚ˆã†ã€ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆã®è¦–ç‚¹ã§ã‚ã‹ã‚Šã‚„ã™ãã¾ã¨ã‚ã¦ã„ã¾ã™*

**ğŸ“± ã‚¹ãƒãƒ›æœ€é©åŒ–**: ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯ã‚¹ãƒãƒ›ã§ã®èª­ã¿ã‚„ã™ã•ã‚’é‡è¦–ã—ã¦ä½œæˆã•ã‚Œã¦ã„ã¾ã™
"""
        return content
    
    def _create_friendly_summary(self, summary: str, article_count: int) -> str:
        """è¦ªã—ã¿ã‚„ã™ã„è¦ç´„ã‚’ä½œæˆ"""
        if article_count == 0:
            return "ä»Šé€±ã¯è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã‚ã§ã—ãŸãŒã€AIãƒ»ITæ¥­ç•Œã¯ç›¸å¤‰ã‚ã‚‰ãšæ´»ç™ºã«å‹•ã„ã¦ã„ã¾ã™ï¼"
        elif article_count < 5:
            return f"ä»Šé€±ã¯{article_count}ä»¶ã®é‡è¦ãªè¨˜äº‹ã‚’ãƒ”ãƒƒã‚¯ã‚¢ãƒƒãƒ—ã€‚è³ªã®é«˜ã„æƒ…å ±ã‚’ãŠå±Šã‘ã—ã¾ã™ ğŸ“°"
        else:
            return f"ä»Šé€±ã¯{article_count}ä»¶ã®è¨˜äº‹ã‹ã‚‰ã€ç‰¹ã«æ³¨ç›®ã™ã¹ããƒˆãƒ¬ãƒ³ãƒ‰ã‚’å³é¸ã—ã¦ã”ç´¹ä»‹ï¼"
    
    def _format_tags_for_light_users(self, top_tags) -> str:
        """ãƒ©ã‚¤ãƒˆå±¤å‘ã‘ã®ã‚¿ã‚°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        if not top_tags:
            return "AIã€æ©Ÿæ¢°å­¦ç¿’ã€ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼å…¨èˆ¬"
        
        friendly_tags = []
        for tag, count in top_tags:
            if 'Claude' in tag:
                friendly_tags.append(f"ğŸ¤– Claude AI ({count}ä»¶)")
            elif 'GitHub' in tag:
                friendly_tags.append(f"ğŸ’» GitHub ({count}ä»¶)")
            elif 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ' in tag:
                friendly_tags.append(f"ğŸ’¬ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæŠ€è¡“ ({count}ä»¶)")
            else:
                friendly_tags.append(f"ğŸ“Œ {tag} ({count}ä»¶)")
        
        return "ã€".join(friendly_tags[:3])
    
    def _generate_light_user_insights(self, top_tags, data) -> str:
        """ãƒ©ã‚¤ãƒˆå±¤å‘ã‘ã®æ´å¯Ÿã‚’ç”Ÿæˆ"""
        insights = []
        
        for tag, count in top_tags[:3]:
            if 'Claude' in tag:
                insights.append("ğŸ¤– **Claude AI**: Anthropicç¤¾ã®AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãŒè©±é¡Œã«ã€‚ChatGPTã®ãƒ©ã‚¤ãƒãƒ«ã¨ã—ã¦æ³¨ç›®åº¦UP")
            elif 'GitHub' in tag:
                insights.append("ğŸ’» **GitHub**: é–‹ç™ºè€…ã®ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã§æ–°æ©Ÿèƒ½ãŒç™»å ´")
            elif 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ' in tag:
                insights.append("ğŸ’¬ **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**: AIã¨ã®å¯¾è©±ã‚¹ã‚­ãƒ«ãŒé‡è¦ã«ã€‚èª°ã§ã‚‚å­¦ã¹ã‚‹æŠ€è¡“ã§ã™")
        
        if not insights:
            insights.append("ğŸ“ˆ **ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼å…¨èˆ¬**: AIãƒ»ITåˆ†é‡ã§ç¶™ç¶šçš„ãªé©æ–°ãŒé€²ã‚“ã§ã„ã¾ã™")
        
        return "\n\n".join(insights)
    
    def _generate_outlook_for_light_users(self, top_tags) -> str:
        """ãƒ©ã‚¤ãƒˆå±¤å‘ã‘ã®å±•æœ›ã‚’ç”Ÿæˆ"""
        return """æ¥é€±ã‚‚å¼•ãç¶šãã€AIæŠ€è¡“ã®é€²åŒ–ã¨å®Ÿç”¨åŒ–ãŒåŠ é€Ÿã—ãã†ã§ã™ã€‚
ç‰¹ã«ã€æ—¥å¸¸ç”Ÿæ´»ã«ã‚ˆã‚Šèº«è¿‘ãªAIã‚µãƒ¼ãƒ“ã‚¹ã®ç™»å ´ã«æ³¨ç›®ã§ã™ï¼

**ğŸ’¡ ãŠã™ã™ã‚ã‚¢ã‚¯ã‚·ãƒ§ãƒ³**: ä»Šé€±ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è¦šãˆã¦ã€å‘¨ã‚Šã®äººã¨ã®ä¼šè©±ã§ä½¿ã£ã¦ã¿ã¦ãã ã•ã„"""
    
    def _generate_glossary_for_tags(self, top_tags) -> str:
        """ã‚¿ã‚°ã«åŸºã¥ãç”¨èªè§£èª¬ã‚’ç”Ÿæˆ"""
        glossary = []
        
        for tag, _ in top_tags[:2]:
            if 'Claude' in tag:
                glossary.append("**Claude**: Anthropicç¤¾ãŒé–‹ç™ºã—ãŸAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€‚è‡ªç„¶ãªå¯¾è©±ãŒå¾—æ„")
            elif 'GitHub' in tag:
                glossary.append("**GitHub**: ãƒ—ãƒ­ã‚°ãƒ©ãƒãƒ¼ãŒã‚³ãƒ¼ãƒ‰ã‚’å…±æœ‰ãƒ»ç®¡ç†ã™ã‚‹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ")
            elif 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ' in tag:
                glossary.append("**ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**: AIã«æŒ‡ç¤ºã‚’å‡ºã™ãƒ†ã‚¯ãƒ‹ãƒƒã‚¯ã€‚ä¸Šæ‰‹ãªè³ªå•ã®ä»•æ–¹")
        
        return "\n".join(glossary) if glossary else "**AI**: äººå·¥çŸ¥èƒ½ã€‚ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ¼ãŒäººé–“ã®ã‚ˆã†ã«è€ƒãˆã‚‹æŠ€è¡“"
    
    def _generate_smart_fallback_report(self, title: str, report_type: str, data: Dict, summary: str, template: 'PromptTemplate') -> str:
        """ãã®ä»–ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå‘ã‘ã®ã‚¹ãƒãƒ¼ãƒˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯"""        
        return f"""# {title}

{summary}

{self._build_report_context(report_type, {"data": data}, summary)}
"""

    def _generate_basic_blog_report(
        self, 
        report_type: str, 
        report_data: Dict[str, Any], 
        summary: str, 
        title: str
    ) -> str:
        """åŸºæœ¬çš„ãªãƒ–ãƒ­ã‚°ãƒ¬ãƒãƒ¼ãƒˆï¼ˆLLMãªã—ã®å ´åˆï¼‰"""
        
        report_content = f"""# {title}

## ã¯ã˜ã‚ã«

ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã¯{report_type}åˆ†æã®çµæœã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚

{summary}

## åˆ†æçµæœ

"""
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ã«å¿œã˜ã¦å†…å®¹ã‚’è¿½åŠ 
        if report_type == "summary":
            data = report_data.get("data", {})
            report_content += f"**ç·è¨˜äº‹æ•°**: {data.get('total_articles', 0)}ä»¶\n\n"
            
            popular_tags = data.get('popular_tags', [])
            if popular_tags:
                report_content += "### äººæ°—ã‚¿ã‚°\n\n"
                for i, (tag, count) in enumerate(popular_tags[:10], 1):
                    report_content += f"{i}. {tag} ({count}ä»¶)\n"
                report_content += "\n"
                
        report_content += f"""
## ã¾ã¨ã‚

{summary}

---
*ç”Ÿæˆæ—¥æ™‚: {datetime.now(pytz.timezone(settings.TIMEZONE)).strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M')}*
"""
        
        return report_content
    
    async def save_report(
        self,
        title: str,
        report_type: str,
        content: str,
        parameters: Optional[Dict[str, Any]] = None,
        raw_data: Optional[Dict[str, Any]] = None,
        summary: Optional[str] = None,
        tags: Optional[List[str]] = None,
        user: Optional[User] = None
    ) -> SavedReport:
        """ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜"""
        
        now = datetime.now(pytz.timezone(settings.TIMEZONE))
        saved_report = SavedReport(
            title=title,
            report_type=report_type,
            content=content,
            parameters=make_json_serializable(parameters or {}),
            raw_data=make_json_serializable(raw_data or {}),
            summary=summary,
            tags=tags or [],
            created_by=str(user.id) if user else None,
            created_at=now,
            updated_at=now
        )
        
        self.db.add(saved_report)
        self.db.commit()
        self.db.refresh(saved_report)
        
        logger.info(f"Saved report: {title} (ID: {saved_report.id})")
        return saved_report
    
    def get_saved_reports(
        self,
        user: Optional[User] = None,
        limit: Optional[int] = None,
        offset: int = 0
    ) -> List[SavedReport]:
        """ä¿å­˜ã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆä¸€è¦§ã‚’å–å¾—"""
        query = self.db.query(SavedReport)
        
        if user:
            query = query.filter(SavedReport.created_by == user.id)
        
        query = query.order_by(SavedReport.created_at.desc()).offset(offset)
        
        if limit is not None:
            query = query.limit(limit)
            
        return query.all()
    
    def get_saved_report(self, report_id: str, user: Optional[User] = None) -> Optional[SavedReport]:
        """ç‰¹å®šã®ä¿å­˜ã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—"""
        query = self.db.query(SavedReport).filter(SavedReport.id == report_id)
        
        if user:
            query = query.filter(SavedReport.created_by == user.id)
        
        return query.first()
    
    def update_saved_report(
        self,
        report_id: str,
        updates: Dict[str, Any],
        user: Optional[User] = None
    ) -> Optional[SavedReport]:
        """ä¿å­˜ã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã‚’æ›´æ–°"""
        report = self.get_saved_report(report_id, user)
        
        if not report:
            return None
        
        # æ›´æ–°å¯èƒ½ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿é©ç”¨
        allowed_fields = ['title', 'content', 'summary', 'tags']
        for field, value in updates.items():
            if field in allowed_fields and hasattr(report, field):
                setattr(report, field, value)
        
        report.updated_at = datetime.now(pytz.timezone(settings.TIMEZONE))
        self.db.commit()
        self.db.refresh(report)
        
        logger.info(f"Updated report: {report_id}")
        return report
    
    def delete_saved_report(self, report_id: str, user: Optional[User] = None) -> bool:
        """ä¿å­˜ã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã‚’å‰Šé™¤"""
        report = self.get_saved_report(report_id, user)
        
        if not report:
            return False
        
        self.db.delete(report)
        self.db.commit()
        
        logger.info(f"Deleted report: {report_id}")
        return True
    
    async def generate_technical_summary_report(
        self,
        keyword: str,
        date_range: Optional[Tuple[datetime, datetime]] = None,
        max_articles: int = 20,
        custom_template: Optional[PromptTemplate] = None
    ) -> str:
        """
        ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®è¨˜äº‹ã«ã¤ã„ã¦ã®æŠ€è¡“ã¾ã¨ã‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ
        
        Args:
            keyword: æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
            date_range: æ—¥ä»˜ç¯„å›²ã®ã‚¿ãƒ—ãƒ« (é–‹å§‹æ—¥, çµ‚äº†æ—¥)
            max_articles: å¯¾è±¡è¨˜äº‹ã®æœ€å¤§æ•°
            custom_template: ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        
        Returns:
            str: ç”Ÿæˆã•ã‚ŒãŸæŠ€è¡“ã¾ã¨ã‚ãƒ¬ãƒãƒ¼ãƒˆ
        """
        try:
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«é–¢é€£ã™ã‚‹è¨˜äº‹ã‚’æ¤œç´¢
            query = self.db.query(Article).filter(
                or_(
                    Article.title.ilike(f"%{keyword}%"),
                    Article.content.ilike(f"%{keyword}%"),
                    Article.summary.ilike(f"%{keyword}%"),
                    Article.tags.op('LIKE')(f'%{keyword}%')
                )
            )
            
            # æ—¥ä»˜ç¯„å›²ãƒ•ã‚£ãƒ«ã‚¿
            if date_range:
                start_date, end_date = date_range
                query = query.filter(
                    and_(
                        Article.published_date >= start_date,
                        Article.published_date <= end_date
                    )
                )
            
            # æ–°ã—ã„é †ã§ã‚½ãƒ¼ãƒˆã—ã€åˆ¶é™ã‚’é©ç”¨
            articles = query.order_by(desc(Article.published_date)).limit(max_articles).all()
            
            if not articles:
                logger.warning(f"No articles found for keyword: {keyword}")
                return f"ã€Œ{keyword}ã€ã«é–¢é€£ã™ã‚‹è¨˜äº‹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
            
            logger.info(f"Found {len(articles)} articles for keyword: {keyword}")
            # ãƒ‡ãƒãƒƒã‚°: æœ€åˆã®è¨˜äº‹ã®è©³ç´°ã‚’è¡¨ç¤º
            if articles:
                first_article = articles[0]
                logger.info(f"First article - Title: {first_article.title[:50]}..., Summary length: {len(first_article.summary) if first_article.summary else 0}")
                logger.info(f"First article - Tags: {first_article.tags}, Source: {first_article.source}")
            
            # è¨˜äº‹ã‚’æ•´ç†ãƒ»åˆ†æ
            technical_content = self._analyze_technical_content(articles, keyword)
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¦ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            if custom_template:
                return await self._generate_with_custom_template(
                    technical_content, custom_template, keyword
                )
            else:
                return await self._generate_default_technical_report(
                    technical_content, keyword
                )
                
        except Exception as e:
            logger.error(f"Error generating technical summary report: {e}")
            raise
    
    def _analyze_technical_content(self, articles: List[Article], keyword: str) -> Dict[str, Any]:
        """è¨˜äº‹ã‚’åˆ†æã—ã¦æŠ€è¡“çš„ãªå†…å®¹ã‚’æ•´ç†"""
        
        # æŠ€è¡“è¦ç´ ã®æŠ½å‡º
        technologies = set()
        concepts = set() 
        sources = defaultdict(int)
        timeline = []
        
        for article in articles:
            # ã‚½ãƒ¼ã‚¹åˆ¥ã®çµ±è¨ˆ
            if article.source:
                sources[article.source] += 1
            
            # ã‚¿ã‚¤ãƒ ãƒ©ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
            timeline.append({
                'date': article.published_date.strftime('%Y-%m-%d'),
                'title': article.title,
                'url': article.url,
                'source': article.source
            })
            
            # ã‚¿ã‚°ã‹ã‚‰æŠ€è¡“è¦ç´ ã‚’æŠ½å‡º
            if article.tags:
                for tag in article.tags:
                    if any(tech_keyword in tag.lower() for tech_keyword in 
                           ['api', 'ai', 'ml', 'python', 'javascript', 'react', 'node', 'docker', 'k8s', 'aws', 'gcp', 'azure']):
                        technologies.add(tag)
                    else:
                        concepts.add(tag)
        
        return {
            'keyword': keyword,
            'total_articles': len(articles),
            'date_range': {
                'start': min(a.published_date for a in articles).strftime('%Y-%m-%d'),
                'end': max(a.published_date for a in articles).strftime('%Y-%m-%d')
            },
            'technologies': sorted(list(technologies)),
            'concepts': sorted(list(concepts)),
            'sources': dict(sources),
            'timeline': sorted(timeline, key=lambda x: x['date'], reverse=True),
            'articles': [
                {
                    'title': a.title,
                    'url': a.url,
                    'summary': a.summary,
                    'source': a.source,
                    'date': a.published_date.strftime('%Y-%m-%d'),
                    'tags': a.tags or []
                }
                for a in articles
            ]
        }
    
    async def _generate_with_custom_template(
        self, 
        content: Dict[str, Any], 
        template: PromptTemplate, 
        keyword: str
    ) -> str:
        """ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã—ã¦ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        try:
            # è¨˜äº‹ã®è©³ç´°æƒ…å ±ã‚’ä½œæˆ
            articles_detailed = self._format_articles_detailed(content['articles'])
            
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå¤‰æ•°ã®æº–å‚™
            template_vars = {
                'keyword': keyword,
                'articles_count': content['total_articles'],
                'date_range_start': content['date_range']['start'],
                'date_range_end': content['date_range']['end'],
                'technologies': ', '.join(content['technologies']) if content['technologies'] else 'æƒ…å ±ãªã—',
                'concepts': ', '.join(content['concepts']) if content['concepts'] else 'æƒ…å ±ãªã—',
                'articles_summary': self._format_articles_for_template(content['articles']),
                'articles_detailed': articles_detailed,
                'sources': ', '.join(content['sources'].keys()) if content['sources'] else 'æƒ…å ±ãªã—'
            }
            
            logger.info(f"Template variables prepared for keyword '{keyword}' with {content['total_articles']} articles")
            logger.info(f"Articles detailed length: {len(articles_detailed)}")
            
            # è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’å¿…ãšå«ã‚ã‚‹ãŸã‚ã®ãƒ™ãƒ¼ã‚¹æƒ…å ±
            article_data_section = f"""
## åˆ†æå¯¾è±¡ã®è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ï¼ˆ{content['total_articles']}ä»¶ï¼‰
{articles_detailed}

## åˆ†ææœŸé–“ãƒ»æ¦‚è¦
- æœŸé–“: {content['date_range']['start']} ï½ {content['date_range']['end']}  
- é–¢é€£æŠ€è¡“: {', '.join(content['technologies']) if content['technologies'] else 'æƒ…å ±ãªã—'}
- ä¸»è¦æ¦‚å¿µ: {', '.join(content['concepts']) if content['concepts'] else 'æƒ…å ±ãªã—'}
- æƒ…å ±ã‚½ãƒ¼ã‚¹: {', '.join(content['sources'].keys()) if content['sources'] else 'æƒ…å ±ãªã—'}
"""

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ç”Ÿæˆ
            if template.user_prompt_template:
                try:
                    # ã‚«ã‚¹ã‚¿ãƒ ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã§ã‚‚è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’å¿…ãšå…ˆé ­ã«è¿½åŠ 
                    formatted_template = template.user_prompt_template.format(**template_vars)
                    user_prompt = f"{article_data_section}\n\n## ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆæŒ‡ç¤º\n{formatted_template}"
                    logger.info("Successfully formatted user prompt template with article data prepended")
                except Exception as format_error:
                    logger.warning(f"Template format error: {format_error}, using fallback with article data")
                    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ + åŸºæœ¬çš„ãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                    user_prompt = f"{article_data_section}\n\nä¸Šè¨˜ã®è¨˜äº‹ã‚’åˆ†æã—ã¦ã€Œ{keyword}ã€ã«ã¤ã„ã¦åˆå¿ƒè€…å‘ã‘ã®æŠ€è¡“è§£èª¬è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
            else:
                # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆãŒãªã„å ´åˆã‚‚è¨˜äº‹ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€
                user_prompt = f"{article_data_section}\n\nä¸Šè¨˜ã®è¨˜äº‹ã‚’åˆ†æã—ã¦ã€Œ{keyword}ã€ã«ã¤ã„ã¦åˆå¿ƒè€…å‘ã‘ã®æŠ€è¡“è§£èª¬è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚"
            
            logger.info(f"Final user prompt length: {len(user_prompt)}")
            
            # LLMã‚µãƒ¼ãƒ“ã‚¹ã‚’ä½¿ç”¨ã—ã¦ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
            response = self.llm_service._api_call_with_retry(
                model=template.model_name or 'claude-sonnet-4-20250514',
                system=template.system_prompt,
                messages=[
                    {
                        "role": "user", 
                        "content": user_prompt
                    }
                ],
                max_tokens=template.max_tokens or 4000,
                temperature=template.temperature or 0.3
            )
            
            return response.content[0].text
            
        except Exception as e:
            logger.error(f"Error with custom template: {e}")
            return await self._generate_default_technical_report(content, keyword)
    
    async def _generate_default_technical_report(
        self, 
        content: Dict[str, Any], 
        keyword: str
    ) -> str:
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®æŠ€è¡“ã¾ã¨ã‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        
        system_prompt = """ã‚ãªãŸã¯æŠ€è¡“ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã®å°‚é–€å®¶ã§ã™ã€‚ä¸ãˆã‚‰ã‚ŒãŸè¨˜äº‹æƒ…å ±ã‚’åŸºã«ã€ç‰¹å®šã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«é–¢ã™ã‚‹æŠ€è¡“ã¾ã¨ã‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ä»¥ä¸‹ã®æ§‹æˆã§åˆ†æã—ã¦ãã ã•ã„ï¼š
1. æŠ€è¡“æ¦‚è¦ - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®ç¾åœ¨ã®çŠ¶æ³ã¨é‡è¦æ€§
2. ä¸»è¦ãªãƒˆãƒ¬ãƒ³ãƒ‰ã¨å‹•å‘ - è¨˜äº‹ã‹ã‚‰èª­ã¿å–ã‚Œã‚‹æŠ€è¡“ã®ç™ºå±•çŠ¶æ³
3. é–¢é€£æŠ€è¡“ã¨ãƒ„ãƒ¼ãƒ« - é–¢é€£ã™ã‚‹æŠ€è¡“è¦ç´ ã®æ•´ç†
4. å®Ÿç”¨äº‹ä¾‹ã¨å¿œç”¨ - å…·ä½“çš„ãªæ´»ç”¨äº‹ä¾‹
5. ä»Šå¾Œã®å±•æœ› - æŠ€è¡“ã®å°†æ¥æ€§ã¨èª²é¡Œ
6. å­¦ç¿’ãƒ»å°å…¥ã®ãŸã‚ã®ãƒªã‚½ãƒ¼ã‚¹ - å‚è€ƒè¨˜äº‹ã®æ•´ç†

æŠ€è¡“çš„ãªæ­£ç¢ºæ€§ã‚’é‡è¦–ã—ã€å…·ä½“çš„ã§å®Ÿç”¨çš„ãªæƒ…å ±ã‚’æä¾›ã—ã¦ãã ã•ã„ã€‚"""

        articles_text = ""
        for i, article in enumerate(content['articles'][:15], 1):  # æœ€å¤§15ä»¶
            summary_text = article.get('summary', 'è¦ç´„ãªã—')
            # è¨˜äº‹ã®è¦ç´„ãŒãªã„å ´åˆã€ã‚¿ã‚¤ãƒˆãƒ«ã‹ã‚‰æ¨æ¸¬
            if not summary_text or len(summary_text.strip()) < 10:
                summary_text = f"è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«: {article.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')}"
            
            articles_text += f"""
{i}. ã€{article.get('title', 'ã‚¿ã‚¤ãƒˆãƒ«ãªã—')}ã€‘({article.get('date', 'æ—¥ä»˜ä¸æ˜')})
   ã‚½ãƒ¼ã‚¹: {article.get('source', 'ä¸æ˜')}
   è¦ç´„: {summary_text[:300]}
   ã‚¿ã‚°: {', '.join(article.get('tags', []))}
   URL: {article.get('url', '')}
"""

        user_prompt = f"""
## åˆ†æå¯¾è±¡è¨˜äº‹ã®è©³ç´°æƒ…å ±ï¼ˆ{content['total_articles']}ä»¶ï¼‰
{articles_text}

## åˆ†æãƒ‡ãƒ¼ã‚¿æ¦‚è¦
- ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰: {keyword}
- å¯¾è±¡è¨˜äº‹æ•°: {content['total_articles']}ä»¶
- åˆ†ææœŸé–“: {content['date_range']['start']} ï½ {content['date_range']['end']}
- é–¢é€£æŠ€è¡“: {', '.join(content['technologies']) if content['technologies'] else 'æƒ…å ±ãªã—'}
- ä¸»è¦æ¦‚å¿µ: {', '.join(content['concepts']) if content['concepts'] else 'æƒ…å ±ãªã—'}

## æŒ‡ç¤º
ä¸Šè¨˜ã®å…·ä½“çš„ãªè¨˜äº‹æƒ…å ±ã‚’åŸºã«ã€ã€Œ{keyword}ã€ã«ã¤ã„ã¦æŠ€è¡“è€…å‘ã‘ã®åŒ…æ‹¬çš„ãªã¾ã¨ã‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
è¨˜äº‹ã®å†…å®¹ã€è¦ç´„ã€ã‚¿ã‚¤ãƒˆãƒ«ã‚’å‚è€ƒã«ã—ã¦ã€å®Ÿéš›ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«åŸºã¥ã„ãŸè§£èª¬ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
"""

        try:
            response = self.llm_service._api_call_with_retry(
                model='claude-sonnet-4-20250514',
                system=system_prompt,
                messages=[
                    {
                        "role": "user",
                        "content": user_prompt
                    }
                ],
                max_tokens=4000,
                temperature=0.3
            )
            
            return response.content[0].text
            
        except Exception as e:
            logger.error(f"Error generating technical report: {e}")
            raise
    
    def _format_articles_for_template(self, articles: List[Dict]) -> str:
        """ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”¨ã«è¨˜äº‹ã‚’æ•´å½¢"""
        formatted = []
        for article in articles[:10]:  # æœ€å¤§10ä»¶
            formatted.append(
                f"- {article['title']} ({article['date']}) - {article['summary'][:100]}..."
            )
        return '\n'.join(formatted)
    
    def _format_articles_detailed(self, articles: List[Dict]) -> str:
        """è©³ç´°ãªè¨˜äº‹æƒ…å ±ã‚’æ•´å½¢"""
        detailed = []
        for i, article in enumerate(articles[:15], 1):  # æœ€å¤§15ä»¶
            content_preview = ""
            if article.get('summary'):
                content_preview = article['summary'][:500]  # ã‚ˆã‚Šé•·ã„è¦ç´„
            
            detailed_info = f"""
ã€è¨˜äº‹ {i}ã€‘{article['title']}
æ—¥ä»˜: {article['date']}
ã‚½ãƒ¼ã‚¹: {article.get('source', 'ä¸æ˜')}
URL: {article.get('url', '')}
ã‚¿ã‚°: {', '.join(article.get('tags', []))}
å†…å®¹: {content_preview}
"""
            detailed.append(detailed_info)
        return '\n'.join(detailed)
    
    def _create_fallback_prompt(self, keyword: str, content: Dict[str, Any], articles_detailed: str) -> str:
        """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ"""
        return f"""
ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã€Œ{keyword}ã€ã«é–¢ã™ã‚‹æŠ€è¡“ã¾ã¨ã‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## åˆ†æãƒ‡ãƒ¼ã‚¿æ¦‚è¦
- å¯¾è±¡è¨˜äº‹æ•°: {content['total_articles']}ä»¶
- åˆ†ææœŸé–“: {content['date_range']['start']} ï½ {content['date_range']['end']}
- é–¢é€£æŠ€è¡“: {', '.join(content['technologies']) if content['technologies'] else 'æƒ…å ±ãªã—'}
- ä¸»è¦æ¦‚å¿µ: {', '.join(content['concepts']) if content['concepts'] else 'æƒ…å ±ãªã—'}
- æƒ…å ±ã‚½ãƒ¼ã‚¹: {', '.join(content['sources'].keys()) if content['sources'] else 'æƒ…å ±ãªã—'}

## åˆ†æå¯¾è±¡è¨˜äº‹ã®è©³ç´°
{articles_detailed}

ä¸Šè¨˜ã®è¨˜äº‹ã‚’åˆ†æã—ã¦ã€ã€Œ{keyword}ã€ã«ã¤ã„ã¦åˆå¿ƒè€…ã«ã‚‚ã‚ã‹ã‚Šã‚„ã™ã„æŠ€è¡“ã¾ã¨ã‚è¨˜äº‹ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚
å…·ä½“çš„ãªè¨˜äº‹ã®å†…å®¹ã¨è¦ç´„ã‚’å‚è€ƒã«ã—ã¦ã€å®Ÿéš›ã®ãƒ‹ãƒ¥ãƒ¼ã‚¹è¨˜äº‹ã«åŸºã¥ã„ãŸè§£èª¬ã‚’è¡Œã£ã¦ãã ã•ã„ã€‚
"""